---

title: 'Deep Learning - 딥러닝 이론 정리 3 (손실함수)'

categories: ['Data Science', 'Deep Learning']

tags: 
- 딥러닝

use_math: true

toc: true
toc_label: "My Table of Contents"
toc_icon: "cog"

---


# 손실함수(LOSS FUNCTION)  
신경망이 학습할 수 있도록 해주는 지표. 손실함수를 최소화 하는 가중치를 찾아가는 과정으로 해결하고자 하는 문제가 어떤 것이냐에 따라 이를 달리하여 원하는 측면에서의 오류를 최소화 하도록 조정할 수 있다.  

## 손실함수의 종류:  
### MeanSquaredError - MSE:  
실제-예측값의 제곱의 합의 평균으로 오차의 정도를 파악하는 지표. 차이가 클 수록 제곱되어 오차의 정도가 뚜렷해진다.  

### RootMeanSquaredError - RMSE:  
오차의 제곱을 한 MSE에 루트를 씌움으로써 실제 오차가 어느 정도인지 파악하기에 좋다.  

<br>


### Binary Crossentropy:  
실제 label과 예측 label 간의 교차 엔트로피 손실을 계산한다. 2개의 label class를 가진 이진분류 문제를 해결할 때 사용. 시그모이드 함수와 짝꿍을 이룬다.  


$L= -\frac{1}{N}\sum_{i=1}^{N}t_ilog(y_i) + (1-t_i)log(1-y_i)$   
예측값과 실제값이 비슷할 수록 손실함수 값은 0에 가까워지고, 오차가 클 수록 양의 무한대로 향한다.  

### Categorical Crossentropy:  
label class가 2개 이상일 때 활성화함수 중 softmax와 함께 연계되어 나온다. 그리하여 softmax loss라고도 표함.  
label이 5개라면, [0,0,1,0,0], [0,1,0,0,0]과 같이 ont-hot 벡터로 제공된다.  

$L= -\frac{1}{N}\sum_{j=1}^{N}\sum_{i=1}^Ct_{ij}log(y_{ij})$  
c = Class 갯수  

### Sparse Categorical Crossentropy:  

Categorical crossentropy와 같이 멀티클래스 분류에 사용되는 손실함수. label이 5개일 때, [0,1,2,3,4]와 같이 정수형으로 나오는 점에서 차이를 보인다.  
